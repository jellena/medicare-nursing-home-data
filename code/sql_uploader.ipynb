{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import glob\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SQL Engine and Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the connection variables\n",
    "Reach out to Karen from TPO or myself for login credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user     = '*****' # Update user name\n",
    "postgres_password = '*****' # Update password\n",
    "postgres_host     = '*****' # Update host address\n",
    "postgres_port     = '*****' # Update port\n",
    "postgres_database = '*****' # Update database name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection code from https://pynative.com/python-postgresql-tutorial/\n",
    "connection = psycopg2.connect(user     = postgres_user,\n",
    "                              password = postgres_password,\n",
    "                              host     = postgres_host,\n",
    "                              port     = postgres_port,\n",
    "                              database = postgres_database)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "# Print PostgreSQL Connection properties\n",
    "print ( connection.get_dsn_parameters(),\"\\n\")\n",
    "\n",
    "# Print PostgreSQL version\n",
    "cursor.execute(\"SELECT version();\")\n",
    "record = cursor.fetchone()\n",
    "print(\"You are connected to - \", record,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Building Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of files in directory\n",
    "files = []\n",
    "for file in glob.glob('.\\data\\*.csv'): # creates relative files paths from current directory\n",
    "    files.append(file.replace('.\\\\data\\\\', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary to replace panda data types with postgres data types\n",
    "dtype_dict = {\n",
    "    'object'  : 'TEXT',\n",
    "    'int64'   : 'INTEGER',\n",
    "    'bool'    : 'BOOLEAN',\n",
    "    'float64' : 'NUMERIC'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_table_builder(files_list):\n",
    "    for file in files_list:\n",
    "        # Temporary dataframe to pull out and format columns names\n",
    "        temp_df = pd.read_csv(f'./data/{file}')\n",
    "        # Converting column names to lower case font, replacing all white space with '_', and removing all '-'\n",
    "        temp_df.columns = temp_df.columns.str.replace(' ', '_').str.replace('-','').str.lower()\n",
    "        # Setting table name\n",
    "        temp_table = file.replace('.csv', '')\n",
    "        # Creating a dictionary of column data types\n",
    "        temp_column_dtypes_dict = dict(temp_df.dtypes)\n",
    "        # Creating the table using the first column in the data frame as the PK\n",
    "        # This column is the same for each data file\n",
    "        cursor.execute(f''' \n",
    "        CREATE TABLE {temp_table} (\n",
    "        {temp_df.columns[0]} TEXT\n",
    "        )''')\n",
    "        # Pushing table to server\n",
    "        connection.commit()\n",
    "        # Iterating through each column but the first\n",
    "        for column in temp_df.columns[1:]:\n",
    "            # Converting the data type of the column into a string\n",
    "            temp_data_type = str(temp_column_dtypes_dict[column])\n",
    "            # Converting the pandas data type into a Postgres data type\n",
    "            temp_data_type_converted = temp_data_type.replace(temp_data_type, dtype_dict[temp_data_type])\n",
    "            # Adding column with converted data type to table\n",
    "            cursor.execute(f'''\n",
    "            ALTER TABLE {temp_table}\n",
    "            ADD COLUMN {column} {temp_data_type_converted};\n",
    "            ''')\n",
    "            connection.commit()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_table_builder(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "Due to superuser rights issues on AWS RDS Postgres servers I was unable to run the code below to update the data on the tables created above. Data was imported from the pgAdmind 4 console using the created tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code below would have been at end of loop above to import data into the newly created table.\n",
    "cursor.execute(f'''\n",
    "COPY {files[0]}({', '.join((str(i) for i in temp_df.columns))})\n",
    "FROM '{os.path.abspath(f'./data/{files[0]}')}'\n",
    "DELIMITER ','\n",
    "CSV HEADER\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
